{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import timing\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = desktop = '/Users/panbingqing/Documents/工作/城市大脑/长沙调控/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取异常处理填充后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camera_id</th>\n",
       "      <th>car_count</th>\n",
       "      <th>date</th>\n",
       "      <th>direction</th>\n",
       "      <th>inter_name</th>\n",
       "      <th>lane</th>\n",
       "      <th>passtime</th>\n",
       "      <th>road_name</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>LB</td>\n",
       "      <td>星沙-滨湖</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-17 00:00:00</td>\n",
       "      <td>星沙-滨湖北</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-05-24</td>\n",
       "      <td>LB</td>\n",
       "      <td>星沙-滨湖</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-24 00:00:00</td>\n",
       "      <td>星沙-滨湖北</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>LB</td>\n",
       "      <td>星沙-滨湖</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-31 00:00:00</td>\n",
       "      <td>星沙-滨湖北</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2019-06-14</td>\n",
       "      <td>LB</td>\n",
       "      <td>星沙-滨湖</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-14 00:00:00</td>\n",
       "      <td>星沙-滨湖北</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>LB</td>\n",
       "      <td>星沙-滨湖</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-05-17 00:03:00</td>\n",
       "      <td>星沙-滨湖北</td>\n",
       "      <td>00:03:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   camera_id  car_count        date direction inter_name  lane  \\\n",
       "0          1        3.0  2019-05-17        LB      星沙-滨湖     1   \n",
       "1          1        6.0  2019-05-24        LB      星沙-滨湖     1   \n",
       "2          1        1.0  2019-05-31        LB      星沙-滨湖     1   \n",
       "3          1        2.0  2019-06-14        LB      星沙-滨湖     1   \n",
       "4          1        1.0  2019-05-17        LB      星沙-滨湖     1   \n",
       "\n",
       "             passtime road_name      time weekday  \n",
       "0 2019-05-17 00:00:00    星沙-滨湖北  00:00:00  Friday  \n",
       "1 2019-05-24 00:00:00    星沙-滨湖北  00:00:00  Friday  \n",
       "2 2019-05-31 00:00:00    星沙-滨湖北  00:00:00  Friday  \n",
       "3 2019-06-14 00:00:00    星沙-滨湖北  00:00:00  Friday  \n",
       "4 2019-05-17 00:03:00    星沙-滨湖北  00:03:00  Friday  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_data = pd.read_csv('/Users/panbingqing/Documents/工作/城市大脑/长沙调控/data_inline/fill_data.csv')\n",
    "fill_data.passtime = pd.to_datetime(fill_data.passtime, format='%Y/%m/%d %H:%M:%S')\n",
    "fill_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 早晚高峰时段判定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_date_mean_by_weekday(data):\n",
    "#     data = data.copy()\n",
    "#     data.index = data.passtime\n",
    "#     data = data.groupby(['inter_name', 'road_name', 'weekday']).resample('15T').car_count.sum().reset_index()\n",
    "#     data['date'] = data.passtime.dt.date\n",
    "#     data['time'] = data.passtime.dt.time\n",
    "#     data = data.groupby(['inter_name', 'road_name', 'time', 'weekday']).car_count.mean()\n",
    "#     data = data.groupby(['inter_name', 'time', 'weekday']).sum().reset_index()\n",
    "#     return data\n",
    "    \n",
    "# weekday_data_15T = get_date_mean_by_weekday(fill_data)\n",
    "# weekday_data_15T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_peak_range(data, peak_time, is_morning=True):\n",
    "#     # 获取高峰时段范围\n",
    "#     data = data[['time', 'car_count']].sort_values(\n",
    "#         'time').reset_index(drop=True).copy()\n",
    "    \n",
    "#     time_range = ([datetime.time(7, 0), datetime.time(10, 0)]\n",
    "#                   if is_morning\n",
    "#                   else [datetime.time(16, 0), datetime.time(22, 0)])\n",
    "    \n",
    "#     range_data = data[(data.time>=time_range[0]) &\n",
    "#                       (data.time<time_range[1])]\n",
    "    \n",
    "#     peak_data = data[(data.time>=peak_time[0]) &\n",
    "#                      (data.time<peak_time[1])]\n",
    "# #     down_limit = peak_data.car_count.max() - (\n",
    "# #         peak_data.car_count.max() - peak_data.car_count.min()) * 1.2\n",
    "#     down_limit = data[data.time == datetime.time(7, 15)].car_count.values[0]\n",
    "    \n",
    "#     peak_range = range_data[range_data.car_count >= down_limit].index\n",
    "#     return data.loc[peak_range[0], 'time'], data.loc[peak_range[-1]+1, 'time']\n",
    "\n",
    "# def get_peak(data):\n",
    "#     # 获取多天高峰时段\n",
    "#     peak_times = []\n",
    "    \n",
    "#     morning_peak_time = [datetime.time(7, 30), datetime.time(9, 0)]\n",
    "#     evening_peak_time = [datetime.time(17, 0), datetime.time(19, 0)]\n",
    "#     for name, group in data.groupby(['inter_name', 'weekday']):\n",
    "#         peak_time = {}\n",
    "#         peak_time['inter_name'] = name[0]\n",
    "#         peak_time['weekday'] = name[1]\n",
    "#         peak_time['morning'] = get_peak_range(group, morning_peak_time)\n",
    "#         peak_time['evening'] = get_peak_range(group, evening_peak_time, is_morning=False)\n",
    "\n",
    "#         peak_times.append(peak_time)\n",
    "#     return peak_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peak_times = get_peak(weekday_data_15T)\n",
    "# peak_data = weekday_data_15T.copy()\n",
    "# peak_data['is_peak'] = None\n",
    "# for peak_time in peak_times:\n",
    "#     for _range in ['morning', 'evening']:\n",
    "#         peak_data.loc[(\n",
    "#             (peak_data.inter_name==peak_time['inter_name']) &\n",
    "#             (peak_data.weekday==peak_time['weekday']) &\n",
    "#             (peak_data.time>=peak_time[_range][0]) &\n",
    "#             (peak_data.time<peak_time[_range][1])\n",
    "#         ), 'is_peak'] = _range\n",
    "#     peak_data.loc[(\n",
    "#         (peak_data.inter_name==peak_time['inter_name']) &\n",
    "#         (peak_data.weekday==peak_time['weekday']) &\n",
    "#         (peak_data.time>=peak_time['morning'][1]) &\n",
    "#         (peak_data.time<peak_time['evening'][0])\n",
    "#     ), 'is_peak'] = 'flat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 天气数据\n",
    "def get_sunny_date(path):\n",
    "    weather = pd.read_csv(path+'长沙天气.csv')\n",
    "    weather.date = pd.to_datetime(weather.date, format='%Y/%m/%d').dt.date\n",
    "    sunny_date = weather.loc[(~weather.weather.str.contains('雨')), 'date']\n",
    "    return sunny_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重采样\n",
    "def resample_data(data, sep='6T'):\n",
    "    # 6分钟重采样\n",
    "    data = data.copy()\n",
    "    data['date'] = data.passtime.dt.date.astype(str)\n",
    "    data.index = data.pop('passtime')\n",
    "    data = data.groupby(\n",
    "        ['inter_name', 'road_name', 'direction', 'lane', 'weekday', 'date']\n",
    "    ).resample(sep).car_count.sum().reset_index()\n",
    "    data['time'] = data.passtime.dt.time\n",
    "    return data\n",
    "\n",
    "def sel_by_time(data, stime, etime):\n",
    "    # 时间筛选\n",
    "    data = data[(data.time >= stime) &\n",
    "                (data.time < etime)]\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunny_date = get_sunny_date(path)\n",
    "\n",
    "# 星沙-望仙/晴天筛选\n",
    "sel_data = fill_data[\n",
    "    (fill_data.inter_name == '星沙-望仙') &\n",
    "    (fill_data.passtime.dt.date.isin(sunny_date))\n",
    "].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 路口全量分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_count</th>\n",
       "      <th>date</th>\n",
       "      <th>inter_name</th>\n",
       "      <th>time</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237.0</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>星沙-望仙</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237.0</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>星沙-望仙</td>\n",
       "      <td>00:15:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>234.0</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>星沙-望仙</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209.0</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>星沙-望仙</td>\n",
       "      <td>00:45:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>225.0</td>\n",
       "      <td>2019-05-17</td>\n",
       "      <td>星沙-望仙</td>\n",
       "      <td>01:00:00</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car_count        date inter_name      time weekday\n",
       "0      237.0  2019-05-17      星沙-望仙  00:00:00  Friday\n",
       "1      237.0  2019-05-17      星沙-望仙  00:15:00  Friday\n",
       "2      234.0  2019-05-17      星沙-望仙  00:30:00  Friday\n",
       "3      209.0  2019-05-17      星沙-望仙  00:45:00  Friday\n",
       "4      225.0  2019-05-17      星沙-望仙  01:00:00  Friday"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veh_count = resample_data(sel_data, sep='15T')\n",
    "road_count = veh_count.groupby(['inter_name', 'road_name', 'weekday', 'date', 'time']).car_count.sum().reset_index()\n",
    "weekday_mean_count = road_count.groupby(['inter_name', 'road_name', 'weekday', 'time']).car_count.mean().reset_index()\n",
    "weekday_mean_count = weekday_mean_count.groupby(['inter_name', 'weekday', 'time']).car_count.sum().reset_index()\n",
    "weekday_mean_count['date'] = 'date_mean'\n",
    "\n",
    "road_count = road_count.groupby(['inter_name', 'weekday', 'date', 'time']).car_count.sum().reset_index()\n",
    "road_count = road_count.append(weekday_mean_count, sort=True)\n",
    "road_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "road_count.to_csv(desktop+'road_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 相关性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_by_date = []\n",
    "for name, group in road_count.groupby(['inter_name', 'weekday']):\n",
    "    for _date in group.date.unique():\n",
    "        if _date == 'date_mean':\n",
    "            continue\n",
    "        relation = {'inter_name': name[0], 'weekday': name[1]}\n",
    "        pivot_table = pd.pivot_table(\n",
    "            group[group.date.isin([_date, 'date_mean'])], index='time', columns='date', values='car_count')\n",
    "        relation['date'] = _date\n",
    "        relation['corr'] = pivot_table.corr().values[0][1]\n",
    "        relation['var_coef'] = pivot_table.std(axis=1).mean() / pivot_table['date_mean'].mean()\n",
    "        relations_by_date.append(relation)\n",
    "        \n",
    "relations_by_date = pd.DataFrame(relations_by_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_by_date.to_csv(path+'relation_by_date.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_of_weekday = {\n",
    "    'Monday': [[datetime.time(7, 15), datetime.time(9, 30)], [datetime.time(16, 15), datetime.time(21, 45)]],\n",
    "    'Tuesday': [[datetime.time(7, 15), datetime.time(10, 0)], [datetime.time(16, 30), datetime.time(21, 45)]],\n",
    "    'Wednesday': [[datetime.time(7, 15), datetime.time(10, 0)], [datetime.time(16, 0), datetime.time(21, 15)]],\n",
    "    'Thursday': [[datetime.time(7, 30), datetime.time(9, 0)], [datetime.time(16, 0), datetime.time(21, 30)]],\n",
    "    'Friday': [[datetime.time(7, 15), datetime.time(11, 0)], [datetime.time(13, 15), datetime.time(22, 45)]],\n",
    "    'Saturday': [[datetime.time(7, 30), datetime.time(22, 15)]],\n",
    "    'Sunday': [[datetime.time(7, 30), datetime.time(22, 15)]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_by_weekday = pd.DataFrame()\n",
    "for name, group in weekday_mean_count.groupby(['inter_name']):\n",
    "    relations = pd.DataFrame()\n",
    "    weekdays = group.weekday.unique()\n",
    "    for weekday_x in weekdays:\n",
    "        for peak_time in peak_of_weekday[weekday_x]:\n",
    "            stime, etime = peak_time\n",
    "            data = group[(group.time>=stime) &\n",
    "                         (group.time<etime)]\n",
    "            pivot_table = pd.pivot_table(\n",
    "                data, index='time', columns='weekday', values='car_count')\n",
    "            relation = pd.DataFrame(pivot_table.corr()[weekday_x])\n",
    "            relation.columns = ['corr']\n",
    "            relation['coef_var'] = 0\n",
    "            \n",
    "            for weekday_y in weekdays:\n",
    "                relation.loc[weekday_y, 'coef_var'] = (\n",
    "                    pivot_table[[weekday_x, weekday_y]].std(axis=1).mean() /\n",
    "                    pivot_table[weekday_x].mean())\n",
    "            \n",
    "            relation['weekday_x'] = weekday_x\n",
    "            relation['peak_range'] = str(stime) + \"-\" + str(etime)\n",
    "            relations = relations.append(relation)\n",
    "    relations['inter_name'] = name\n",
    "    relations_by_weekday = relations_by_weekday.append(relations)\n",
    "relations_by_weekday = relations_by_weekday.reset_index().rename(columns={'weekday': 'weekday_y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "relations_by_weekday.to_csv(path+'relations_by_weekday.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 配时计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 获取weekday_label，及根据weekday_label求算均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh_count = resample_data(sel_data, '6T')\n",
    "veh_count['weekday_label'] = veh_count.weekday\n",
    "\n",
    "new_weekday_label = veh_count[\n",
    "    veh_count.weekday.isin(['Monday', 'Tuesday', 'Wednesday', 'Thursday'])\n",
    "].copy()\n",
    "new_weekday_label['weekday_label'] = 'Monday_Thursday'\n",
    "\n",
    "veh_count = veh_count.append(new_weekday_label, sort=True)\n",
    "\n",
    "weekday_label_mean = veh_count.groupby(\n",
    "    ['inter_name', 'road_name', 'direction', 'lane', 'time', 'weekday_label']\n",
    "    ).car_count.mean().reset_index(name='car_count')\n",
    "weekday_label_mean['date'] = 'date_mean'\n",
    "\n",
    "weekday_mean = weekday_label_mean[\n",
    "    weekday_label_mean.weekday_label!='Monday_Thursday'\n",
    "].groupby(\n",
    "    ['inter_name', 'road_name', 'direction', 'lane', 'time', 'date']\n",
    "    ).car_count.mean().reset_index(name='car_count')\n",
    "weekday_mean['weekday_label'] = 'weekday_mean'\n",
    "\n",
    "new_veh_count = veh_count[\n",
    "    ['inter_name', 'road_name', 'direction', 'lane', 'time', 'weekday_label', 'date', 'car_count']\n",
    "    ].append(weekday_label_mean, ignore_index=True, sort=True\n",
    "            ).append(weekday_mean, ignore_index=True, sort=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge相位信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase_info(path):\n",
    "    # 获取相位信息\n",
    "    phase_info = pd.read_csv('/Users/panbingqing/Documents/工作/城市大脑/长沙调控/lane_info.csv')[['road_name', 'direction', 'phase']]\n",
    "    phase_info.drop_duplicates(['road_name', 'direction'], inplace=True)\n",
    "    phase_info.dropna(inplace=True)\n",
    "    return phase_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_info = get_phase_info('data/info/')\n",
    "phase_data = new_veh_count.merge(phase_info, how='left', on=['road_name', 'direction'])\n",
    "# 不受信号灯控制的，相位名称以R表示\n",
    "phase_data.phase.fillna('R', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_data.to_csv(path+'phase_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 关键相位流量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 关键相位流量为相位中单车道最大值\n",
    "key_phase_data = phase_data.groupby(\n",
    "    ['inter_name', 'time', 'weekday_label', 'date', 'phase']\n",
    "    ).car_count.max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_key_phase(key_phase, columns):\n",
    "    # key_phase nan 值填充\n",
    "    groups =  key_phase.groupby(columns)\n",
    "    key_phase = pd.DataFrame()\n",
    "    for name, group in groups:\n",
    "        group = group.pivot_table(index='time', columns='phase', values='car_count')\n",
    "        group.fillna(method='pad', inplace=True)\n",
    "        group = group.unstack().reset_index()\n",
    "        for i, col in enumerate(columns):\n",
    "            group[col] = name[i]\n",
    "        group.rename(columns={0: 'car_count'}, inplace=True)\n",
    "        key_phase = key_phase.append(group)\n",
    "    return key_phase\n",
    "key_phase_data = fill_key_phase(key_phase_data, ['inter_name', 'weekday_label', 'date'])\n",
    "key_phase_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phase_data.to_csv(path+'key_phase_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_phase_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 配时计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配时计算根据weekday_label均值进行计算\n",
    "key_phase_data_weekday = key_phase_data[\n",
    "    (key_phase_data.date == 'date_mean') & \n",
    "    (key_phase_data.phase != 'R')\n",
    "].reset_index(drop=True).copy()\n",
    "key_phase_data_weekday['sat_flow_ratio'] = 1440 / 60 * 6\n",
    "\n",
    "timing_data = pd.DataFrame()\n",
    "groups = key_phase_data_weekday.groupby(['inter_name', 'time', 'weekday_label'])\n",
    "for name, group in groups:\n",
    "    data = group.reset_index(drop=True)\n",
    "    phase_data = timing.timing(data)\n",
    "    data['phase_time'] = phase_data.phase_time\n",
    "    data['cycle'] = phase_data.cycle\n",
    "    timing_data = timing_data.append(data)\n",
    "timing_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge peak time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_of_weekday = {\n",
    "    'Monday': {'morning_peak': [datetime.time(7, 15), datetime.time(9, 30)],\n",
    "               'day_flat': [datetime.time(9, 30), datetime.time(16, 15)],\n",
    "               'evening_peak': [datetime.time(16, 15), datetime.time(21, 45)]},\n",
    "    'Tuesday': {'morning_peak': [datetime.time(7, 15), datetime.time(10, 0)], \n",
    "                'day_flat': [datetime.time(10, 0), datetime.time(16, 30)],\n",
    "                'evening_peak': [datetime.time(16, 30), datetime.time(21, 45)]},\n",
    "    'Wednesday': {'morning_peak': [datetime.time(7, 15), datetime.time(10, 0)],\n",
    "                  'day_flat': [datetime.time(10, 0), datetime.time(16, 0)],\n",
    "                  'evening_peak': [datetime.time(16, 0), datetime.time(21, 15)]},\n",
    "    'Thursday': {'morning_peak': [datetime.time(7, 30), datetime.time(9, 0)],\n",
    "                 'day_flat': [datetime.time(9, 0), datetime.time(16, 0)],\n",
    "                 'evening_peak': [datetime.time(16, 0), datetime.time(21, 30)]},\n",
    "    'Friday': {'morning_peak': [datetime.time(7, 15), datetime.time(11, 0)],\n",
    "               'day_flat': [datetime.time(11, 0), datetime.time(13, 15)],\n",
    "               'evening_peak': [datetime.time(13, 15), datetime.time(22, 45)]},\n",
    "    'Saturday': {'day_flat': [datetime.time(7, 30), datetime.time(22, 15)]},\n",
    "    'Sunday': {'day_flat': [datetime.time(7, 30), datetime.time(22, 15)]},\n",
    "    'Monday_Thursday': {'morning_peak': [datetime.time(7, 15), datetime.time(9, 30)],\n",
    "                        'day_flat': [datetime.time(9, 30), datetime.time(16, 15)],\n",
    "                        'evening_peak': [datetime.time(16, 15), datetime.time(21, 45)]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data['peak_type'] = 'evening_flat'\n",
    "for weekday, peak_times in peak_of_weekday.items():\n",
    "    for _type, _time in peak_times.items():\n",
    "        timing_data.loc[(timing_data.weekday_label == weekday) &\n",
    "                        (timing_data.time >= _time[0]) &\n",
    "                        (timing_data.time < _time[1]), 'peak_type'] = _type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根据相位时间、周期长进行分层聚类，筛选time_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(data, n_clusters=6, adjust_label=True):\n",
    "    '''\n",
    "    adjust_label: boolean; 对离散的label取临近调整\n",
    "    '''\n",
    "    cluster_data = data.copy()\n",
    "    cluster_data.index = cluster_data.pop('time')\n",
    "    \n",
    "    # 根据相位时间和时间顺序进行聚类\n",
    "    x_data = cluster_data.pivot_table(index='time', columns='phase', values='phase_time')\n",
    "    x_data['n'] = [x * 6 for x in range(len(x_data))]\n",
    "#         cycle = label_data.groupby('time').cycle.mean()\n",
    "#         data = pd.DataFrame({'cycle': cycle,\n",
    "#                              'n': [x+1 for x in range(len(cycle))]})\n",
    "    cluster_label = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward').fit(x_data).labels_\n",
    "\n",
    "    adjust_label = True\n",
    "    while adjust_label:\n",
    "        adjust_label = 0\n",
    "        for i in range(1, len(x_data)-1):\n",
    "            if (cluster_label[i] != cluster_label[i-1]) and (cluster_label[i] != cluster_label[i+1]):\n",
    "                cluster_label[i] = cluster_label[i-1]\n",
    "                adjust_label += 1\n",
    "\n",
    "    cluster_data['cluster_label'] = pd.Series(cluster_label, index=x_data.index)\n",
    "    return cluster_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = timing_data.groupby(['inter_name', 'weekday_label', 'peak_type'])\n",
    "cluster_datas = pd.DataFrame()\n",
    "for name, group in groups:\n",
    "    n_clusters = 1\n",
    "    if name[2] in ['morning_peak', 'evening_peak']:\n",
    "        n_clusters = 5\n",
    "    cluster_data = get_cluster(group, n_clusters)\n",
    "    cluster_datas = cluster_datas.append(cluster_data)\n",
    "cluster_datas.reset_index(drop=True, inplace=True)\n",
    "cluster_datas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = cluster_datas.groupby(['inter_name', 'weekday_label', 'peak_type', 'cluster_label', 'phase'])\n",
    "new_cluster_datas = pd.DataFrame()\n",
    "for name, group in groups:\n",
    "    data = group.copy()\n",
    "    data['cluster_phase_time'] = timing.label_mean(data.phase_time)\n",
    "    new_cluster_datas = new_cluster_datas.append(data)\n",
    "new_cluster_datas.reset_index(drop=True, inplace=True)\n",
    "new_cluster_datas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cluster_datas.to_csv(desktop+'timing_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
